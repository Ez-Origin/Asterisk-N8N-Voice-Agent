---
description: Development rules and guidelines for the Asterisk AI Voice Agent v3.0 project
globs: src/**/*.py, *.py, docker-compose.yml, Dockerfile, config/ai-agent.yaml
alwaysApply: true
---

# Asterisk AI Voice Agent v3.0 - Development Rules

## Project Overview
This is an open-source AI Voice Agent that integrates with Asterisk/FreePBX using the Asterisk REST Interface (ARI). It features a **two-container, modular architecture** that uses Asterisk's native **AudioSocket** feature for reliable real-time audio capture and **file-based playback** for robust media handling.

## Development Workflow

### Test Server Configuration
- **Server**: <internal test host>
- **Asterisk Version**: 16+ with FreePBX UI
- **Docker**: Installed and available
- **Access**: SSH with appropriate privileges
- **Shared Media Directory**: A `tmpfs` (RAM disk) is mounted at `/mnt/asterisk_media` for high-performance, temporary audio file storage.

### Development Process
1. **Local Development**: All code changes are made locally on the `develop` branch.
2. **Git Workflow**: 
   - Build and verify locally.
   - Commit changes to Git.
   - Push to remote `develop` branch.
3. **Server Testing**:
   - SSH to test server.
   - For isoloated tests scp file to the server and then to the container
   - `git pull` the latest changes into `/root/Asterisk-Agent-Develop`.
   - Use `docker-compose restart` for code changes or `docker-compose up --build -d` for dependency changes.

### Docker Development Workflow (CRITICAL)

**NEVER rebuild the Docker image for code changes in the `ai-engine`.** Use the volume-based workflow:

1. **For dependency changes only**: `docker-compose up --build -d`
2. **For `ai-engine` code changes**: `docker-compose restart ai-engine` (instant)
3. **View logs**: `docker-compose logs -f`

### Project Structure
```
Asterisk-AI-Voice-Agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ providers/          # AI provider integrations
â”‚   â”‚   â”œâ”€â”€ base.py         # AIProviderInterface abstract class
â”‚   â”‚   â”œâ”€â”€ deepgram.py     # Deepgram provider
â”‚   â”‚   â””â”€â”€ local.py        # Local provider (WebSocket client)
â”‚   â”œâ”€â”€ ari_client.py       # ARI client for call control and playback
â”‚   â”œâ”€â”€ audiosocket_server.py # NEW: TCP server for receiving AudioSocket stream
â”‚   â”œâ”€â”€ config.py           # YAML configuration loader
â”‚   â””â”€â”€ engine.py           # Core call orchestration
â”œâ”€â”€ local_ai_server/        # Standalone server for local AI models
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â””â”€â”€ ai-agent.yaml       # Main configuration file
â”œâ”€â”€ models/                 # Local AI models (mounted to local-ai-server)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_models.sh
â”œâ”€â”€ main.py                 # Application entry point for ai-engine
â”œâ”€â”€ docker-compose.yml      # Two-service orchestration
â”œâ”€â”€ Dockerfile              # Dockerfile for ai-engine
â””â”€â”€ requirements.txt        # Dependencies for ai-engine
```

### Key Technologies
- **Asterisk Integration**: ARI for call control and **AudioSocket** for real-time audio capture.
- **Audio Processing**: All real-time media (RTP) is handled natively by Asterisk. The application receives a raw audio stream via TCP and commands media playback via ARI.
- **Conversation Management**: Asyncio-based AudioSocket server for real-time two-way audio conversations.
- **Provider Isolation**: Independent AI providers (Local, Deepgram, OpenAI) with configuration-based switching.

### Current Implementation Status
- **âœ… COMPLETED**: Two-container architecture, provider system, one-way audio (greeting playback)
- **âœ… COMPLETED**: Local AI Server, Deepgram provider, provider switching, file management
- **ðŸš§ IN PROGRESS**: Two-way audio conversation (real-time STT â†’ LLM â†’ TTS pipeline)
- **ðŸ“‹ PLANNED**: OpenAI provider, production readiness, installation automation

### Environment Variables
Configuration is primarily managed in `config/ai-agent.yaml`. The `.env` file is only used for secrets.

- `ASTERISK_HOST`: IP address of your Asterisk server.
- `ASTERISK_ARI_USERNAME`: <your_ari_user>
- `ASTERISK_ARI_PASSWORD`: <your_ari_password>
- Provider-specific API keys (e.g., `DEEPGRAM_API_KEY`, `OPENAI_API_KEY`).

Key flags (documented in `config/ai-agent.yaml`):
- `audio_transport`: `audiosocket` (recommended) | `legacy`
- `downstream_mode`: `file` (current default) | `stream` (next phase)

## ARI Integration and Call Handling

### Call Flow: AudioSocket/Playback Model

The new architecture provides a guaranteed media path by leveraging Asterisk's AudioSocket feature, treating our application as a pure controller.

1.  **Call Initiation**: A new call enters a dialplan context that first calls the `AudioSocket()` application, then the `Stasis()` application.
2.  **Audio Stream Starts**: Asterisk establishes a TCP connection to the `AudioSocketServer` running inside the `ai-engine` and immediately begins streaming raw audio.
3.  **StasisStart**: The `Engine` receives the `StasisStart` event via ARI, determines the provider, and answers the call.
4.  **Real-time Conversation**:
    -   The `AudioSocketServer` receives raw audio chunks and forwards them to the active AI provider.
    -   The provider processes the audio (STT -> LLM -> TTS) with interruption handling and barge-in detection.
5.  **Media Playback**:
    -   The provider sends the synthesized TTS audio back to the `ai-engine`.
    -   The `AriClient` writes this audio to a unique file in the shared directory.
    -   It sends a `channels.play` command to Asterisk, telling it to play the sound file.
6.  **Cleanup**:
    -   The `AriClient` listens for the `PlaybackFinished` event from Asterisk.
    -   The event handler immediately deletes the audio file from the shared directory.

This model is the most robust and performant, avoiding the unreliable `ChannelAudioFrame` events and the complexity of manual RTP handling.

## Real-Time Conversation Management

### AudioSocket Server Pattern
The core of two-way audio functionality is the `AudioSocketServer` class that manages the TCP connection and audio streaming:

```python
class AudioSocketServer:
    def __init__(self, port: int = 8090):
        self.port = port
        self.active_connections = {}  # Per-call connection management
        self.provider_manager = None
    
    async def start_server(self):
        # Start TCP server on specified port
        # Handle incoming connections from Asterisk
    
    async def handle_connection(self, reader, writer):
        # Process real-time audio stream
        # Forward to active AI provider
        # Manage connection lifecycle
```

### State Management
Each call maintains its own state with explicit transitions:
- **Connecting**: Establishing AudioSocket TCP connection
- **Streaming**: Receiving real-time audio from caller
- **Processing**: STT â†’ LLM â†’ TTS pipeline execution
- **Speaking**: Playing TTS audio to caller
- **Idle**: Waiting for next input

### Connection Management
- **Per-call Isolation**: Each call gets its own TCP connection
- **Connection Pooling**: Manage multiple concurrent connections
- **Error Recovery**: Automatic reconnection on connection loss
- **Resource Cleanup**: Ensure connections are closed on call end

### Performance Targets (Current)
- Conversational latency optimized via tmpfs and minimal I/O
- End-to-End Response: target P95 < 2 seconds

### Next Phase: Streaming TTS (Feature-Flagged)
- Fullâ€‘duplex streaming over AudioSocket; bargeâ€‘in support
- Add jitter buffers and downstream backpressure
- Keep legacy file playback as fallback

### Concurrency Patterns
- **Per-call Isolation**: Each call gets its own AudioSocket connection
- **Task Registry**: Track all asyncio tasks per call for coordinated cancellation
- **Connection Management**: Use asyncio for TCP connection handling
- **Resource Cleanup**: Ensure all connections and tasks are cleaned up on call end

## Testing and Verification

### Comprehensive Test Suite

The project includes a comprehensive test suite designed to systematically verify each component of the two-container architecture.

#### Test Files
- **`test_local_ai_server.py`**: Tests the Local AI Server container (STT, LLM, TTS functionality)
- **`test_ai_engine.py`**: Tests the AI Engine container (ARI connectivity, audio playback)
- **`test_integration.py`**: Tests end-to-end integration between containers

#### Test Execution Workflow

1. **Pre-Deployment Testing**:
   ```bash
   # Test Local AI Server
   docker exec local_ai_server python /app/test_local_ai_server.py
   
   # Test AI Engine
   docker exec ai_engine python /app/test_ai_engine.py
   
   # Test Integration
   docker exec ai_engine python /app/test_integration.py
   ```

2. **Live Call Testing**:
   - Monitor logs during test calls
   - Verify greeting audio playback
   - Test real-time conversation flow

#### Test Results Documentation
- All test results are documented in `docs/Individual-Tests.md`
- Test files are deployed to server for live testing
- Regular test execution ensures system reliability

### Critical Testing Points

- **AudioSocket Server**: Must start and accept connections on port 8090
- **TCP Connection Management**: Must handle multiple concurrent calls
- **Audio Format Handling**: Must process ulaw audio correctly
- **Provider Integration**: Must forward audio to correct provider
- **File Playback**: Must successfully play generated audio to callers
- **Connection Cleanup**: Must properly close connections on call end
- **Pipeline Orchestration**: Must coordinate STT â†’ LLM â†’ TTS flow with proper error handling
- **Provider Isolation**: Changes to one provider must not impact others

### Troubleshooting Guide

#### Systematic Troubleshooting Methodology (Established September 2025)

**Core Principle**: "Break it down step by step, each iteration till we reach the correct way to fix this permanently."

**Step-by-Step Process**:
1. **Isolate the Problem**: Test individual components in isolation
2. **Verify Each Step**: Don't assume anything works until verified
3. **Use Direct Testing**: Test from inside containers when possible
4. **Check Asterisk Logs**: Always verify actual playback success, not just command acceptance
5. **Document Findings**: Log each discovery with timestamps

**Critical Discovery - Asterisk File Extension Handling**:
- **Root Cause**: Asterisk automatically appends file extensions to `sound:` URIs
- **Issue**: `sound:ai-generated/response-xxx.ulaw` becomes `response-xxx.ulaw.ulaw`
- **Solution**: Remove `.ulaw` extension from URI: `sound:ai-generated/response-xxx`
- **Impact**: This affects ALL audio playback, not just AI-generated files

**AudioSocket-Specific Troubleshooting**:
- **Connection Testing**: Verify AudioSocket server is running on port 8090
- **Dialplan Verification**: Check Asterisk dialplan has correct AudioSocket configuration
- **TCP Connectivity**: Test connection from Asterisk to container
- **Audio Stream Analysis**: Monitor raw audio data flow
- **Connection Management**: Check per-call connection handling

**General Troubleshooting Tools**:
- **Direct ARI Testing**: Create test scripts inside containers to test ARI commands directly
- **File Verification**: Check file creation, permissions, and format
- **Asterisk Log Analysis**: Monitor `/var/log/asterisk/full` for actual playback events
- **Symlink Verification**: Ensure proper symlink setup for file access
- **Format Validation**: Verify audio format compatibility with Asterisk

When issues arise:
1. Check AudioSocket server logs for connection status
2. Verify Asterisk dialplan configuration
3. Test TCP connectivity to port 8090
4. Monitor audio stream processing
5. Check provider integration and response times
6. Verify file-based playback functionality
7. Run individual component tests to isolate problems
8. Check container logs for specific error messages
