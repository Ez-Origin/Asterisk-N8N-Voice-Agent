version: "3.8"

services:
  # Redis Message Queue
  redis:
    image: "redis:alpine"
    container_name: "asterisk-ai-voice-agent-redis"
    restart: unless-stopped
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # RTPEngine Media Proxy
  rtpengine:
    build:
      context: .
      dockerfile: services/rtpengine/Dockerfile
    container_name: asterisk-ai-voice-agent-rtpengine
    command: rtpengine --listen-ng=2223 --interface=172.20.0.3 -L 7 --log-stderr
    privileged: true
    ports:
      - "2223:2223" # Control port
      - "10000-10009:10000-10009/udp" # RTP port range
    restart: unless-stopped
    cap_add:
      - NET_ADMIN
      - SYS_NICE

  # Call Controller Service
  call_controller:
    build:
      context: .
      dockerfile: services/call_controller/Dockerfile
    container_name: asterisk-ai-voice-agent-call-controller
    restart: unless-stopped
    ports:
      - "15000:5000"
    volumes:
      - shared_audio:/shared/audio
      - shared_logs:/shared/logs
    depends_on:
      redis:
        condition: service_healthy
      rtpengine:
        condition: service_started
    networks:
      - ai-voice-network
    env_file:
      - .env

  stt_service:
    build:
      context: .
      dockerfile: services/stt_service/Dockerfile
    restart: unless-stopped
    ports:
      - "18001:8001"
      - "5004:5004/udp"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    environment:
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - shared_audio:/shared/audio
      - shared_logs:/shared/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ai-voice-network
    env_file:
      - .env

  llm_service:
    build:
      context: .
      dockerfile: services/llm_service/Dockerfile
    restart: unless-stopped
    ports:
      - "18002:8002"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    environment:
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - FALLBACK_LLM_MODEL=${FALLBACK_LLM_MODEL:-gpt-3.5-turbo}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - shared_logs:/shared/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ai-voice-network
    env_file:
      - .env

  tts_service:
    build:
      context: .
      dockerfile: services/tts_service/Dockerfile
    restart: unless-stopped
    ports:
      - "18003:8003"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    environment:
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - shared_audio:/shared/audio
      - shared_logs:/shared/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ai-voice-network
    env_file:
      - .env

volumes:
  redis_data:
    driver: local
  rtpengine_data:
    driver: local
  shared_audio:
    driver: local
  shared_logs:
    driver: local

networks:
  ai-voice-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16