version: "3.8"

services:
  # Redis Message Queue
  redis:
    image: redis:7.2-alpine
    container_name: asterisk-ai-voice-agent-redis
    restart: always
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    network_mode: host

  # RTPEngine Media Proxy
  rtpengine:
    build:
      context: .
      dockerfile: services/rtpengine/Dockerfile
      no_cache: true
    container_name: asterisk-ai-voice-agent-rtpengine
    command: rtpengine --listen-ng=172.20.0.3:2223 --interface=172.20.0.3 -L 7 --log-stderr
    privileged: true
    ports:
      - "2223:2223" # Control port
      - "10000-10009:10000-10009/udp" # RTP port range
    restart: unless-stopped
    networks:
      ai-voice-network:
        ipv4_address: 172.20.0.3
    cap_add:
      - NET_ADMIN
      - SYS_NICE

  # Call Controller Service
  call_controller:
    build:
      context: .
      dockerfile: services/call_controller/Dockerfile
      no_cache: true
    container_name: asterisk-ai-voice-agent-call-controller
    restart: always
    ports:
      - "15000:5000"
    extra_hosts:
      - "voiprnd.nemtclouddispatch.com:45.79.181.39"
    volumes:
      - shared_audio:/shared/audio
      - shared_logs:/shared/logs
    depends_on:
      redis:
        condition: service_healthy
    network_mode: host
    env_file:
      - .env
    environment:
      - ASTERISK_HOST=127.0.0.1
      - REDIS_URL=redis://127.0.0.1:6379
      - RTPENGINE_HOST=127.0.0.1

  stt_service:
    build:
      context: .
      dockerfile: services/stt_service/Dockerfile
      no_cache: true
    restart: unless-stopped
    ports:
      - "18001:8001"
      - "5004:5004/udp"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - shared_audio:/shared/audio
      - shared_logs:/shared/logs
    depends_on:
      redis:
        condition: service_healthy
    network_mode: host
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://127.0.0.1:6379

  llm_service:
    build:
      context: .
      dockerfile: services/llm_service/Dockerfile
      no_cache: true
    restart: unless-stopped
    ports:
      - "18002:8002"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - shared_logs:/shared/logs
      - ./services/llm_service/fallback_responses.json:/app/fallback_responses.json
    depends_on:
      redis:
        condition: service_healthy
    network_mode: host
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://127.0.0.1:6379

  tts_service:
    build:
      context: .
      dockerfile: services/tts_service/Dockerfile
      no_cache: true
    restart: unless-stopped
    ports:
      - "18003:8003"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - shared_audio:/shared/audio
      - shared_logs:/shared/logs
    depends_on:
      redis:
        condition: service_healthy
    network_mode: host
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://127.0.0.1:6379

volumes:
  redis_data:
    driver: local
  rtpengine_data:
    driver: local
  shared_audio:
    driver: local
  shared_logs:
    driver: local

networks:
  ai-voice-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16