# config/ai-agent.yaml
# Default provider to use if not specified in the dialplan
default_provider: "local"

# Audio transport controls
# - audio_transport: 'audiosocket' (recommended) | 'externalmedia' | 'legacy'
# - downstream_mode: 'file' (current default) | 'stream' (next phase)
audio_transport: "externalmedia"
downstream_mode: "file"

# Asterisk connection settings (will be overridden by environment variables)
asterisk:
  host: "your_asterisk_host"
  username: "your_ari_username"
  password: "your_ari_password"
  app_name: "asterisk-ai-voice-agent"

# External Media configuration for RTP-based audio capture
external_media:
  rtp_host: "0.0.0.0"      # target IP for ExternalMedia (localhost for host networking)
  rtp_port: 18080            # fixed port for simplicity
  codec: "ulaw"              # ulaw (8k) or slin16 (8k)
  direction: "both"          # sendrecv | sendonly | recvonly
  jitter_buffer_ms: 20       # target frame size

# RTP server settings for External Media (legacy - kept for compatibility)
rtp:
  host: "127.0.0.1"
  port_range: [10000, 10100]  # Range of UDP ports for RTP communication
  sample_rate: 8000
  samples_per_packet: 160  # 20ms at 8kHz

# Global LLM settings (will be overridden by environment variables)
llm:
  initial_greeting: "Hello, how can I help you today?"
  prompt: "You are a friendly and helpful assistant."
  model: "gpt-4o"
  api_key: "${OPENAI_API_KEY}" # Example of using env var substitution

# Streaming settings (used when downstream_mode == 'stream')
streaming:
  sample_rate_hz: 16000      # PCM16 sample rate for providers that require conversion
  chunk_duration_ms: 20      # Audio chunk size
  jitter_buffer_ms: 120      # Downstream jitter buffer target
  keepalive_ms: 2000         # Gateway/provider heartbeat interval (reduced to keep AudioSocket alive)
  timeouts:
    provider_ms: 15000       # Provider operation timeout
    handshake_ms: 5000       # AudioSocket handshake timeout
  barge_in:
    enabled: false           # Enable in streaming mode to support barge-in
    vad_threshold_db: -30    # Voice activity threshold
    min_speech_ms: 200       # Minimum speech duration to trigger barge-in
    # WebRTC VAD configuration
    vad_backend: "hybrid"    # "energy" | "webrtc" | "hybrid" (default: hybrid)
    webrtc_aggressiveness: 0 # WebRTC VAD aggressiveness 0-3 (0 is least aggressive, 3 is most aggressive)
    webrtc_start_frames: 3   # Consecutive speech frames to start recording

# VAD Configuration - Optimized for 4+ second utterances
vad:
  # WebRTC VAD settings
  webrtc_aggressiveness: 0   # Least aggressive (0-3) for telephony audio
  webrtc_start_frames: 3     # Consecutive frames to start recording
  webrtc_end_silence_frames: 50  # Silence frames to end recording (1000ms)
  
  # Utterance settings - optimized for 4+ second duration
  min_utterance_duration_ms: 4000  # Minimum 4 seconds for accurate STT
  max_utterance_duration_ms: 10000 # Maximum 10 seconds
  utterance_padding_ms: 200        # Padding before/after speech
  
  # Fallback settings
  fallback_enabled: true           # Enable fallback when VAD fails
  fallback_interval_ms: 4000       # Send audio every 4 seconds as fallback
  fallback_buffer_size: 128000     # 4 seconds of 16kHz audio (128,000 bytes)

# Provider-specific configurations
providers:
  deepgram:
    api_key: "${DEEPGRAM_API_KEY}"
    model: "nova-2"
    tts_model: "aura-asteria-en"

  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o"
    voice: "alloy"

  local:
    enabled: true
    stt_model: "models/stt/vosk-model-small-en-us-0.15"
    llm_model: "models/llm/llama-2-7b-chat.Q4_K_M.gguf"
    tts_voice: "tts_models/en/ljspeech/tacotron2-DDC"
    temperature: 0.8
    max_tokens: 150
