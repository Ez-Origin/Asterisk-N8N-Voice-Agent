# Monolithic OpenAI Realtime Voice Agent configuration
# Copy to config/ai-agent.yaml to run the OpenAI Realtime agent (no pipelines required).
# Requires OPENAI_API_KEY in .env

default_provider: "openai_realtime"

# Transport modes
audio_transport: "audiosocket"   # audiosocket | externalmedia
downstream_mode: "stream"        # stream | file

audiosocket:
  host: "0.0.0.0"
  port: 8090
  format: "ulaw"

# Optional: barge-in and streaming tuning
barge_in:
  enabled: false
  initial_protection_ms: 400    # Drop inbound during agent intro; 200–600 ms. Higher = less echo, more delay.
  min_ms: 400                   # Sustained speech required to trigger; 250–600 ms. Lower = more sensitive.
  energy_threshold: 1800        # RMS threshold for speech detection; 1000–3000. Raise on noisy lines.
  cooldown_ms: 1000             # Ignore retriggers for this period after one fires; 500–1500 ms.
  post_tts_end_protection_ms: 250  # Guard after TTS ends to avoid clipping callers; 250–500 ms.

streaming:
  sample_rate: 8000
  jitter_buffer_ms: 100
  keepalive_interval_ms: 5000
  connection_timeout_ms: 10000
  fallback_timeout_ms: 8000
  chunk_size_ms: 20
  min_start_ms: 300
  low_watermark_ms: 200
  provider_grace_ms: 500
  logging_level: "info"

providers:
  openai_realtime:
    enabled: true
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o-realtime-preview-2024-12-17"
    voice: "alloy"
    base_url: "wss://api.openai.com/v1/realtime"
    # Optional: enable server-side VAD turn detection for improved turn-taking.
    # turn_detection:
    #   type: "server_vad"
    #   silence_duration_ms: 200
    #   threshold: 0.5
    #   prefix_padding_ms: 200

# Canonical LLM defaults (used by provider unless overridden)
llm:
  initial_greeting: "Hello, how can I help you today?"
  prompt: "You are a concise and helpful voice assistant. Keep replies under 20 words unless asked for detail."
  model: "gpt-4o"
