# config/ai-agent.yaml
# Default provider to use if not specified in the dialplan
default_provider: "local"

# Audio transport controls
# - audio_transport: 'audiosocket' (recommended) | 'external_media' | 'legacy'
# - downstream_mode: 'file' (current default) | 'stream' (next phase)
audio_transport: "audiosocket"
downstream_mode: "file"

# Asterisk connection settings (will be overridden by environment variables)
asterisk:
  host: "your_asterisk_host"
  username: "your_ari_username"
  password: "your_ari_password"
  app_name: "asterisk-ai-voice-agent"

# RTP server settings for External Media
rtp:
  host: "127.0.0.1"
  port_range: [10000, 10100]  # Range of UDP ports for RTP communication
  sample_rate: 8000
  samples_per_packet: 160  # 20ms at 8kHz

# Global LLM settings (will be overridden by environment variables)
llm:
  initial_greeting: "Hello, how can I help you today?"
  prompt: "You are a friendly and helpful assistant."
  model: "gpt-4o"
  api_key: "${OPENAI_API_KEY}" # Example of using env var substitution

# Streaming settings (used when downstream_mode == 'stream')
streaming:
  sample_rate_hz: 16000      # PCM16 sample rate for providers that require conversion
  chunk_duration_ms: 20      # Audio chunk size
  jitter_buffer_ms: 120      # Downstream jitter buffer target
  keepalive_ms: 2000         # Gateway/provider heartbeat interval (reduced to keep AudioSocket alive)
  timeouts:
    provider_ms: 15000       # Provider operation timeout
    handshake_ms: 5000       # AudioSocket handshake timeout
  barge_in:
    enabled: false           # Enable in streaming mode to support barge-in
    vad_threshold_db: -30    # Voice activity threshold
    min_speech_ms: 200       # Minimum speech duration to trigger barge-in

# Provider-specific configurations
providers:
  deepgram:
    api_key: "${DEEPGRAM_API_KEY}"
    model: "nova-2"
    tts_model: "aura-asteria-en"

  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o"
    voice: "alloy"

  local:
    enabled: true
    stt_model: "models/stt/vosk-model-small-en-us-0.15"
    llm_model: "models/llm/llama-2-7b-chat.Q4_K_M.gguf"
    tts_voice: "tts_models/en/ljspeech/tacotron2-DDC"
    temperature: 0.8
    max_tokens: 150
