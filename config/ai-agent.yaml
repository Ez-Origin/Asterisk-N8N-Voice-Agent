# config/ai-agent.yaml
# Default provider to use if not specified in the dialplan
default_provider: "openai_realtime"

# Pipeline definitions specify which STT/LLM/TTS components power each call.
# Pipelines can mix local and cloud services; the orchestrator selects components
# based on `active_pipeline`. Per-component options override defaults (base URLs,
# models, voices, codec formats, etc.).
pipelines:
  # Hosted OpenAI realtime stack across STT/LLM/TTS. Requires OPENAI_API_KEY for bearer auth.
  default:
    stt: openai_stt
    llm: openai_llm
    tts: openai_tts
    options:
      stt:
        base_url: "https://api.openai.com/v1/realtime"  # Bearer auth with OPENAI_API_KEY
      llm:
        base_url: "https://api.openai.com/v1"
        model: "gpt-4o-realtime-preview-2024-12-17"
      tts:
        base_url: "https://api.openai.com/v1/audio/speech"
        format:
          encoding: "linear16"  # Provider emits PCM16 frames used by streaming mode
          sample_rate: 24000    # Engine resamples to downstream target sample rate as needed
  # Fully local inference pipeline; runs entirely inside local_ai_server.
  local_only:
    stt: local_stt
    llm: local_llm
    tts: local_tts
    options:
      stt:
        mode: "stt"  # Restrict local provider to speech recognition only
      tts:
        format:
          encoding: "mulaw"  # Matches telephony trunks without resampling
          sample_rate: 8000
  # Hybrid pipeline: local STT + OpenAI LLM + Deepgram Aura TTS.
  local_stt_cloud_tts:
    stt: local_stt
    llm: openai_llm
    tts: deepgram_tts
    options:
      stt:
        mode: "stt"  # Local provider ingests AudioSocket frames for recognition
      llm:
        base_url: "https://api.openai.com/v1"
        model: "gpt-4o"  # Uses OPENAI_API_KEY via bearer auth
      tts:
        base_url: "https://api.deepgram.com"  # Requires DEEPGRAM_API_KEY
        format:
          encoding: "mulaw"  # Deepgram Aura emits 8 kHz μ-law ready for playback
          sample_rate: 8000
  # Cloud vendor mix: Deepgram STT + Google Gemini LLM + Google TTS.
  cloud_only:
    stt: deepgram_stt
    llm: google_llm
    tts: google_tts
    options:
      stt:
        base_url: "https://api.deepgram.com"  # Authenticates with DEEPGRAM_API_KEY
        language: "en-US"  # See Deepgram docs for supported locales
      llm:
        base_url: "https://generativelanguage.googleapis.com/v1"
        model: "models/gemini-1.5-pro-latest"  # Requires Google API credentials
      tts:
        base_url: "https://texttospeech.googleapis.com/v1"
        voice_name: "en-US-Neural2-C"
        audio_config:
          audio_encoding: "MULAW"  # Telephony μ-law output for direct playback
          sample_rate_hz: 8000

active_pipeline: "local_only"

# Audio transport controls (AudioSocket-first, ExternalMedia as fallback)
#
# Tuning notes:
# - `audio_transport`: prefer `audiosocket` for full-duplex PCM over TCP; use `externalmedia` for RTP.
# - `downstream_mode`:
#     - `stream`: streams agent audio in 20 ms frames in real time.
#     - `file`: plays μ-law files via bridge; more tolerant but higher latency.
audio_transport: "audiosocket"
downstream_mode: "stream"

# AudioSocket listener configuration (when audio_transport=audiosocket)
audiosocket:
  host: "0.0.0.0"          # Bind address (use 127.0.0.1 when engine and Asterisk share a host)
  port: 8090               # TCP port for AudioSocket connections
  format: "slin16"         # Wire format from Asterisk: `ulaw` (160B/20ms) or `slin16` (320B/20ms) at 8 kHz
                           # TIP: Keep provider input sample rate aligned to 8 kHz when using telephony trunks.

# Barge-in configuration
barge_in:
  enabled: true
  initial_protection_ms: 400   # Drop inbound during the initial TTS window (avoids early self-echo)
                               # Range: 200–600 ms (higher if trunks echo or agent intros are long)
  min_ms: 400                  # Sustained speech required to trigger barge-in (de-bounce)
                               # Range: 250–600 ms (lower = more sensitive barge-in)
  energy_threshold: 1800       # RMS threshold for speech detection (telephony baseline)
                               # Range: 1000–3000 (raise on noisy lines)
  cooldown_ms: 1000            # Ignore new barge-in triggers for this period after one fires
                               # Range: 500–1500 ms
  post_tts_end_protection_ms: 350  # NEW: Drop inbound right after TTS ends to prevent self-echo loops
                                   # Range: 250–500 ms (lower to allow faster user pickup)

# Streaming configuration (for downstream_mode=stream)
streaming:
  sample_rate: 8000          # Output sample rate for streaming audio
  jitter_buffer_ms: 100      # Jitter buffer target depth; increase for jittery networks (e.g., 80–150). Higher = more robust, slightly higher latency.
  keepalive_interval_ms: 5000 # Keepalive interval for streaming connections
  connection_timeout_ms: 10000 # Connection timeout for streaming
  fallback_timeout_ms: 8000   # No audio sent for this long → fall back to file playback
  chunk_size_ms: 20          # Frame size; 20 ms recommended for telephony cadence
  min_start_ms: 300          # Warm-up buffer before first frame; 250–400 ms recommended for natural, click-free starts.
  low_watermark_ms: 200      # Pause streaming when buffer dips below this watermark; rebuild depth to avoid underruns.
  provider_grace_ms: 500     # Absorb late provider chunks after stream cleanup (ms); prevents tail-chop artifacts.
  logging_level: "info"      # Optional override for streaming logger verbosity

# Asterisk connection settings (will be overridden by environment variables)
asterisk:
  host: "your_asterisk_host"
  username: "your_ari_username"
  password: "your_ari_password"
  app_name: "asterisk-ai-voice-agent"

# External Media configuration for RTP-based audio capture
external_media:
  rtp_host: "0.0.0.0"      # target IP for ExternalMedia (localhost for host networking)
  rtp_port: 18080            # fixed port for simplicity
  codec: "ulaw"              # ulaw (8k) or slin16 (8k)
  direction: "both"          # sendrecv | sendonly | recvonly
  jitter_buffer_ms: 20       # target frame size


# Global LLM settings (will be overridden by environment variables)
llm:
  initial_greeting: "Hello, how can I help you today?"
  prompt: "You are a concise and helpful voice assistant. Keep replies under 20 words unless asked for detail."
  model: "gpt-4o"
  api_key: "${OPENAI_API_KEY}" # Example of using env var substitution


# VAD Configuration - Optimized for 4+ second utterances
vad:
  # WebRTC VAD settings
  webrtc_aggressiveness: 0   # Least aggressive (0-3) for telephony audio
  webrtc_start_frames: 3     # Consecutive frames to start recording
  webrtc_end_silence_frames: 50  # Silence frames to end recording (1000ms)
  
  # Utterance settings - optimized for 4+ second duration
  min_utterance_duration_ms: 4000  # Minimum 4 seconds for accurate STT
  max_utterance_duration_ms: 10000 # Maximum 10 seconds
  utterance_padding_ms: 200        # Padding before/after speech
  
  # Fallback settings
  fallback_enabled: true           # Enable fallback when VAD fails
  fallback_interval_ms: 4000       # Send audio every 4 seconds as fallback
  fallback_buffer_size: 128000     # 4 seconds of 16kHz audio (128,000 bytes)

# Provider-specific configurations
providers:
  local:
    enabled: true
    ws_url: "${LOCAL_WS_URL:-ws://127.0.0.1:8765}"
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=2.0}
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=200}
    stt_model: "models/stt/vosk-model-small-en-us-0.15"   # legacy placeholder (Local AI server now loads via env vars)
    llm_model: "models/llm/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf"
    tts_voice: "models/tts/en_US-lessac-medium.onnx"
    temperature: 0.4
    max_tokens: 64
  deepgram:
    enabled: true
    api_key: "${DEEPGRAM_API_KEY}"
    model: "nova-2-general"
    tts_model: "aura-asteria-en"
    greeting: "${DEEPGRAM_GREETING:-Hello, how can I help you today?}"
    instructions: "${DEEPGRAM_INSTRUCTIONS:-You are a concise voice assistant. Respond in under 20 words and answer immediately.}"
    input_encoding: "linear16"   # Provider audio encoding for inbound caller audio
    input_sample_rate_hz: 8000    # Align to trunk sample rate (8 kHz for telephony)
    continuous_input: true        # Stream audio continuously for best responsiveness
                                  # TIP: Keep this true for real-time conversations
  openai:
    enabled: true
    api_key: "${OPENAI_API_KEY}"
    organization: "${OPENAI_ORG:-}"
    project: "${OPENAI_PROJECT:-}"
    realtime_base_url: "wss://api.openai.com/v1/realtime"
    chat_base_url: "https://api.openai.com/v1"
    tts_base_url: "https://api.openai.com/v1/audio/speech"
    realtime_model: "gpt-4o-realtime-preview-2024-12-17"
    chat_model: "gpt-4o-mini"
    tts_model: "gpt-4o-mini-tts"
    voice: "alloy"
    default_modalities:
      - "text"
    input_encoding: "linear16"
    input_sample_rate_hz: 16000
    target_encoding: "mulaw"
    target_sample_rate_hz: 8000
    chunk_size_ms: 20
    response_timeout_sec: 5.0
  openai_realtime:
    enabled: true
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o-realtime-preview-2024-12-17"
    voice: "alloy"
    base_url: "wss://api.openai.com/v1/realtime"
    instructions: "You are a concise voice assistant. Respond clearly and keep answers under 20 words unless more detail is requested."
    organization: ""
    input_encoding: "slin16"          # AudioSocket inbound PCM16 @ 8 kHz
    input_sample_rate_hz: 8000
    output_encoding: "linear16"       # Provider emits PCM16 frames
    output_sample_rate_hz: 24000
    target_encoding: "ulaw"  # Explicit for file playback; update if enabling streaming PCM
    target_sample_rate_hz: 8000
    response_modalities:
      - "audio"
      - "text"
    # Explicit greeting said immediately on connect via response.create
    greeting: "${OPENAI_GREETING:-Hello, how can I help you today?}"
    # Optional: enable server-side VAD turn detection to improve turn handling
    turn_detection:
      type: "server_vad"
      silence_duration_ms: 200
      threshold: 0.5
      prefix_padding_ms: 200
