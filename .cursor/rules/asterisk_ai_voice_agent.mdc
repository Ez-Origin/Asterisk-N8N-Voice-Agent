---
description: Development rules and guidelines for the Asterisk AI Voice Agent v3.0 project
globs: src/**/*.py, *.py, docker-compose.yml, Dockerfile, config/ai-agent.yaml
alwaysApply: true
---

# Asterisk AI Voice Agent v3.0 - Development Rules

## Project Overview
This is an open-source AI Voice Agent that integrates with Asterisk/FreePBX using the Asterisk REST Interface (ARI). It features a **two-container, modular architecture** that uses Asterisk's native **Snoop/Playback** capabilities for robust media handling.

## Development Workflow

### Test Server Configuration
- **Server**: `root@voiprnd.nemtclouddispatch.com`
- **Asterisk Version**: 16+ with FreePBX UI
- **Docker**: Installed and available
- **Access**: SSH with root privileges
- **Shared Media Directory**: A `tmpfs` (RAM disk) is mounted at `/mnt/asterisk_media` for high-performance, temporary audio file storage.

### Development Process
1. **Local Development**: All code changes are made locally on the `develop` branch.
2. **Git Workflow**: 
   - Build and verify locally.
   - Commit changes to Git.
   - Push to remote `develop` branch.
3. **Server Testing**:
   - SSH to test server.
   - `git pull` the latest changes into `/root/Asterisk-Agent-Develop`.
   - Use `docker-compose restart` for code changes or `docker-compose up --build -d` for dependency changes.

### Docker Development Workflow (CRITICAL)

**NEVER rebuild the Docker image for code changes in the `ai-engine`.** Use the volume-based workflow:

1. **For dependency changes only**: `docker-compose up --build -d`
2. **For `ai-engine` code changes**: `docker-compose restart ai-engine` (instant)
3. **View logs**: `docker-compose logs -f`

### Project Structure
```
Asterisk-AI-Voice-Agent/
├── src/
│   ├── providers/          # AI provider integrations
│   │   ├── base.py         # AIProviderInterface abstract class
│   │   ├── deepgram.py     # Deepgram provider
│   │   └── local.py        # Local provider (WebSocket client)
│   ├── ari_client.py       # ARI client using Snoop/Playback
│   ├── config.py           # YAML configuration loader
│   └── engine.py           # Core call orchestration
├── local_ai_server/        # Standalone server for local AI models
│   ├── Dockerfile
│   ├── main.py
│   └── requirements.txt
├── config/
│   └── ai-agent.yaml       # Main configuration file
├── models/                 # Local AI models (mounted to local-ai-server)
├── scripts/
│   └── download_models.sh
├── main.py                 # Application entry point for ai-engine
├── docker-compose.yml      # Two-service orchestration
├── Dockerfile              # Dockerfile for ai-engine
└── requirements.txt        # Dependencies for ai-engine
```

### Key Technologies
- **Asterisk Integration**: ARI via a custom `ari_client` implementing the Snoop/Playback model.
- **Audio Processing**: All real-time media (RTP) is handled natively by Asterisk. The application controls media flow via ARI commands.

### Environment Variables
Configuration is primarily managed in `config/ai-agent.yaml`. The `.env` file is only used for secrets.

- `ASTERISK_HOST`: IP address of your Asterisk server.
- `ASTERISK_ARI_USERNAME`: AIAgent
- `ASTERISK_ARI_PASSWORD`: AiAgent+2025?
- And other provider-specific API keys.

## ARI Integration and Call Handling

### Call Flow: Snoop/Playback Model

The new architecture simplifies the media path by leveraging Asterisk's native capabilities, treating our application as a pure controller.

1.  **StasisStart**: A new call enters the `ai-voice-agent` Stasis application.
    -   The `Engine` receives the event, determines the provider, and answers the call.
2.  **Media Setup (Audio Input)**:
    -   The `AriClient` creates a **snoop channel** on the incoming call. This provides a direct, raw audio stream of the caller's media via ARI WebSocket events (`ChannelAudioFrame`).
3.  **Real-time Conversation**:
    -   The `AriClient` receives audio frames and forwards them to the active AI provider (e.g., the `local-ai-server`).
    -   The provider processes the audio (STT -> LLM -> TTS).
4.  **Media Setup (Audio Output)**:
    -   The provider sends the synthesized TTS audio (as a `.wav` byte stream) back to the `ai-engine`.
    -   The `AriClient` writes this audio to a unique file in the shared RAM-based directory (`/mnt/asterisk_media`).
    -   It sends a `channels.play` command to Asterisk, telling it to play the sound file.
5.  **Cleanup**:
    -   The `AriClient` listens for the `PlaybackFinished` event from Asterisk.
    -   The event handler immediately deletes the audio file from the shared directory.
6.  **StasisEnd**: When the call hangs up, the `Engine` cleans up any remaining resources.

This model eliminates the need for a UDP server and manual RTP handling, resulting in a more stable and simplified system.

## Testing and Verification

### Comprehensive Test Suite

The project includes a comprehensive test suite designed to systematically verify each component of the two-container architecture.

#### Test Files
- **`test_local_ai_server.py`**: Tests the Local AI Server container (STT, LLM, TTS functionality)
- **`test_ai_engine.py`**: Tests the AI Engine container (ARI connectivity, audio playback)
- **`test_integration.py`**: Tests end-to-end integration between containers

#### Test Execution Workflow

1. **Pre-Deployment Testing**:
   ```bash
   # Test Local AI Server
   docker exec local_ai_server python /app/test_local_ai_server.py
   
   # Test AI Engine
   docker exec ai_engine python /app/test_ai_engine.py
   
   # Test Integration
   docker exec ai_engine python /app/test_integration.py
   ```

2. **Live Call Testing**:
   - Monitor logs during test calls
   - Verify greeting audio playback
   - Test real-time conversation flow

#### Test Results Documentation
- All test results are documented in `docs/Individual-Tests.md`
- Test files are deployed to server for live testing
- Regular test execution ensures system reliability

### Critical Testing Points

- **TTS Functionality**: Must generate audio for greetings and responses
- **WebSocket Communication**: Must maintain stable connection between containers
- **ARI Integration**: Must properly create snoop channels and handle audio frames
- **Audio Playback**: Must successfully play generated audio to callers

### Troubleshooting Guide

When issues arise:
1. Run individual component tests to isolate problems
2. Check container logs for specific error messages
3. Verify model loading and initialization
4. Test WebSocket connectivity between containers
5. Validate ARI commands and responses
