---
description: Development rules and guidelines for the Asterisk AI Voice Agent v3.0 project
globs: src/**/*.py, *.py, docker-compose.yml, Dockerfile, config/ai-agent.yaml
alwaysApply: true
---

# Asterisk AI Voice Agent v3.0 - Development Rules

## Project Overview
This is an open-source AI Voice Agent that integrates with Asterisk/FreePBX using the Asterisk REST Interface (ARI). It features a **single-container, modular architecture** that allows for plug-and-play AI providers (including local and cloud-based) for real-time, natural conversations.

## Development Workflow

### Test Server Configuration
- **Server**: `root@voiprnd.nemtclouddispatch.com`
- **Asterisk Version**: 16+ with FreePBX UI
- **Docker**: Installed and available
- **Access**: SSH with root privileges

### Development Process
1. **Local Development**: All code changes are made locally on the `develop` branch.
2. **Git Workflow**:
   - Build and verify locally.
   - Commit changes to Git.
   - Push to remote `develop` branch.
3. **Server Testing**:
   - SSH to test server.
   - Clone `develop` branch into `/root/Asterisk-Agent-Develop`.
   - Bring down the main production container if up and bring up the develop container for isolated testing.
   - Test with Asterisk 16+ environment.
   - Do not make any changes to asterisk config on server, ask user to do so if needed.

### Docker Development Workflow (CRITICAL)

**NEVER rebuild the Docker image for code changes.** Use the volume-based workflow:

1. **For dependency changes only**: `docker-compose up --build -d`
2. **For code changes**: `docker-compose restart` (instant)
3. **View logs**: `docker-compose logs -f`

**Key Principles:**
- Source code is mounted as volumes, not copied into the image
- Only rebuild when `requirements.txt` or `Dockerfile` changes
- Use `docker-compose restart` for all Python code changes
- This reduces deployment time from 15 minutes to under 10 seconds

**Development Commands:**
```bash
# Initial setup (run once)
./scripts/download_models.sh
docker-compose up --build -d

# Daily development (code changes)
docker-compose restart
docker-compose logs -f

# Cleanup
docker-compose down
```

**Volume-Based Development:**
- **Source Code**: Mount `./src`, `./config`, `./main.py` as volumes
- **Models**: Mount `./models` directory for AI models
- **No Rebuilds**: Use `docker-compose restart` for code changes
- **Build Only**: When `requirements.txt` or `Dockerfile` changes

### Code Standards
- **Python Version**: 3.11+
- **Async Programming**: Use asyncio for all I/O operations
- **Type Hints**: Required for all functions and classes
- **Error Handling**: Comprehensive error handling with logging
- **Testing**: Unit tests for all components.

### Project Structure
```
Asterisk-AI-Voice-Agent/
├── src/
│   ├── providers/          # AI provider integrations (Deepgram, Local)
│   │   ├── base.py         # AIProviderInterface abstract class
│   │   ├── deepgram.py     # Deepgram provider
│   │   └── local.py        # Local provider (Vosk, Llama, Piper)
│   ├── ari_client.py       # ARI WebSocket and HTTP client
│   ├── config.py           # YAML configuration loader and Pydantic models
│   ├── engine.py           # Core call orchestration and provider loading
│   ├── rtp_handler.py      # RTP packetization logic
│   └── udp_server.py       # UDP server for receiving RTP from Asterisk
├── config/
│   └── ai-agent.yaml       # Main configuration file for providers
├── models/                 # Local AI models (downloaded by script, not in git)
│   ├── stt/
│   └── llm/
│   └── tts/
├── scripts/
│   └── download_models.sh  # Script to fetch local AI models
├── main.py                 # Application entry point
├── docker-compose.yml      # Single-service orchestration
├── Dockerfile              # Multi-stage optimized container
└── requirements.txt        # Python dependencies
```

### Key Technologies
- **Asterisk Integration**: ARI (Asterisk REST Interface) via custom `ari_client`
- **AI Providers**:
    - **Cloud**: Deepgram Voice Agent
    - **Local STT**: Vosk
    - **Local LLM**: Llama-cpp-python
    - **Local TTS**: Piper-tts
- **Configuration**: YAML (`ai-agent.yaml`) with Pydantic v2 for validation
- **Audio Processing**: RTP packet handling, ulaw/PCM conversion

### Common Commands

**Fast Development Workflow (OPTIMIZED):**

```bash
# 1. One-Time Setup: Download Local AI Models
./scripts/download_models.sh

# 2. Initial Build (only when dependencies change)
docker-compose up --build -d

# 3. Code Changes (INSTANT - use this for all Python changes)
docker-compose restart

# 4. View Logs
docker-compose logs -f

# 5. Stop Application
docker-compose down

# 6. Clean up
docker image prune -f
```

**Server Testing Workflow (UPDATED):**

```bash
# On test server: /root/Asterisk-Agent-Develop
git pull origin develop
docker-compose restart  # Instant code updates
docker-compose logs -f

# When testing complete
docker-compose down

# Restart production if needed
docker-compose -f /root/Asterisk-AI-Voice-Agent/docker-compose.yml up -d
```

### Environment Variables
Configuration is primarily managed in `config/ai-agent.yaml`. The `.env` file is only used for secrets.

- `OPENAI_API_KEY`: Your OpenAI API key.
- `DEEPGRAM_API_KEY`: Your Deepgram API key.
- `ASTERISK_HOST`: IP address of your Asterisk server.
- `ASTERISK_ARI_USERNAME`: ARI username.
- `ASTERISK_ARI_PASSWORD`: ARI password.
- `GREETING`: The initial greeting the AI speaks.
- `AI_ROLE`: The system prompt for the LLM.

### Testing Commands
```bash
# Verify ARI connection
asterisk -rx "ari show app asterisk-ai-voice-agent"

# Check Asterisk status
asterisk -rx "core show version"

# Monitor Asterisk logs
tail -f /var/log/asterisk/full

# Test call command 
asterisk -rx "channel originate sip/13164619284@callcentric application s@ivr-3"
```

## ARI Integration and Call Handling

### Call Flow
The new single-container architecture simplifies call handling significantly.

1.  **StasisStart**: A new call enters the `ai-voice-agent` Stasis application.
    -   The `Engine` receives the event.
    -   The dialplan argument (e.g., "deepgram" or "local") is used to determine which AI provider to use.
    -   The `Engine` instantiates the appropriate provider class (e.g., `DeepgramProvider`).
2.  **Media Setup**:
    -   The `Engine` answers the call.
    -   It creates an `externalMedia` channel, which sets up a UDP port for Asterisk to send RTP audio to.
    -   The incoming channel and the media channel are placed into a bridge.
3.  **Real-time Conversation**:
    -   The `UDPServer` receives RTP packets from Asterisk.
    -   The raw audio payload is forwarded to the active AI provider's `send_audio` method.
    -   The provider's STT engine transcribes the audio.
    -   The text is sent to the provider's LLM.
    -   The LLM's text response is sent to the provider's TTS engine.
    -   The synthesized audio is received by the `Engine`, packetized into RTP, and sent back to Asterisk via the UDP port.
4.  **StasisEnd**: When the call hangs up, the `Engine`'s `_cleanup_call` method is triggered.
    -   The provider's `stop_session` method is called.
    -   The bridge is destroyed and all channels are hung up.

This entire loop occurs within a single process, eliminating the need for Redis-based inter-service communication and external media proxies like rtpengine.

## Docker Optimization Rules

### Multi-Stage Dockerfile Requirements
- **Stage 1 (builder)**: Use `python:3.11` for building dependencies
- **Stage 2 (final)**: Use `python:3.11-slim` for runtime
- **Layer Caching**: Copy `requirements.txt` before source code
- **Security**: Run as non-root user (`appuser`)
- **Virtual Environment**: Use `/opt/venv` for dependency isolation

### Volume-Based Development
- **Source Code**: Mount `./src`, `./config`, `./main.py` as volumes
- **Models**: Mount `./models` directory for AI models
- **No Rebuilds**: Use `docker-compose restart` for code changes
- **Build Only**: When `requirements.txt` or `Dockerfile` changes

### Performance Targets
- **Initial Build**: ~15 minutes (acceptable, happens once)
- **Code Changes**: <10 seconds (99% improvement)
- **Dependency Changes**: ~15 minutes (only when needed)

This workflow ensures maximum developer productivity while maintaining production-ready container images.
