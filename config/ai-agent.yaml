# config/ai-agent.yaml
# Default provider to use if not specified in the dialplan
default_provider: "deepgram"

# Audio transport controls (AudioSocket-first, ExternalMedia as fallback)
#
# Tuning notes:
# - `audio_transport`: prefer `audiosocket` for full-duplex PCM over TCP; use `externalmedia` for RTP.
# - `downstream_mode`:
#     - `stream`: streams agent audio in 20 ms frames in real time.
#     - `file`: plays μ-law files via bridge; more tolerant but higher latency.
audio_transport: "audiosocket"
downstream_mode: "stream"

# AudioSocket listener configuration (when audio_transport=audiosocket)
audiosocket:
  host: "0.0.0.0"          # Bind address (use 127.0.0.1 when engine and Asterisk share a host)
  port: 8090               # TCP port for AudioSocket connections
  format: "slin16"         # Wire format from Asterisk: `ulaw` (160B/20ms) or `slin16` (320B/20ms) at 8 kHz
                           # TIP: Keep provider input sample rate aligned to 8 kHz when using telephony trunks.

# Barge-in configuration
barge_in:
  enabled: true
  initial_protection_ms: 400   # Drop inbound during the initial TTS window (avoids early self-echo)
                               # Range: 200–600 ms (higher if trunks echo or agent intros are long)
  min_ms: 400                  # Sustained speech required to trigger barge-in (de-bounce)
                               # Range: 250–600 ms (lower = more sensitive barge-in)
  energy_threshold: 1800       # RMS threshold for speech detection (telephony baseline)
                               # Range: 1000–3000 (raise on noisy lines)
  cooldown_ms: 1000            # Ignore new barge-in triggers for this period after one fires
                               # Range: 500–1500 ms
  post_tts_end_protection_ms: 350  # NEW: Drop inbound right after TTS ends to prevent self-echo loops
                                   # Range: 250–500 ms (lower to allow faster user pickup)

# Streaming configuration (for downstream_mode=stream)
streaming:
  sample_rate: 8000          # Output sample rate for streaming audio
  jitter_buffer_ms: 50       # Jitter buffer target depth; increase for jittery networks (e.g., 80–120)
  keepalive_interval_ms: 5000 # Keepalive interval for streaming connections
  connection_timeout_ms: 10000 # Connection timeout for streaming
  fallback_timeout_ms: 8000   # No audio sent for this long → fall back to file playback
  chunk_size_ms: 20          # Frame size; 20 ms recommended for telephony cadence
  min_start_ms: 160          # Warm-up buffer before first frame; 120–200 ms typical
  low_watermark_ms: 80       # Pause streaming when buffer dips below this watermark
  provider_grace_ms: 500     # Absorb late provider chunks after stream cleanup
  logging_level: "info"      # Optional override for streaming logger verbosity

# Asterisk connection settings (will be overridden by environment variables)
asterisk:
  host: "your_asterisk_host"
  username: "your_ari_username"
  password: "your_ari_password"
  app_name: "asterisk-ai-voice-agent"

# External Media configuration for RTP-based audio capture
external_media:
  rtp_host: "0.0.0.0"      # target IP for ExternalMedia (localhost for host networking)
  rtp_port: 18080            # fixed port for simplicity
  codec: "ulaw"              # ulaw (8k) or slin16 (8k)
  direction: "both"          # sendrecv | sendonly | recvonly
  jitter_buffer_ms: 20       # target frame size


# Global LLM settings (will be overridden by environment variables)
llm:
  initial_greeting: "Hello, how can I help you today?"
  prompt: "You are a concise and helpful voice assistant. Keep replies under 20 words unless asked for detail."
  model: "gpt-4o"
  api_key: "${OPENAI_API_KEY}" # Example of using env var substitution


# VAD Configuration - Optimized for 4+ second utterances
vad:
  # WebRTC VAD settings
  webrtc_aggressiveness: 0   # Least aggressive (0-3) for telephony audio
  webrtc_start_frames: 3     # Consecutive frames to start recording
  webrtc_end_silence_frames: 50  # Silence frames to end recording (1000ms)
  
  # Utterance settings - optimized for 4+ second duration
  min_utterance_duration_ms: 4000  # Minimum 4 seconds for accurate STT
  max_utterance_duration_ms: 10000 # Maximum 10 seconds
  utterance_padding_ms: 200        # Padding before/after speech
  
  # Fallback settings
  fallback_enabled: true           # Enable fallback when VAD fails
  fallback_interval_ms: 4000       # Send audio every 4 seconds as fallback
  fallback_buffer_size: 128000     # 4 seconds of 16kHz audio (128,000 bytes)

# Provider-specific configurations
providers:
  local:
    enabled: false
    stt_model: "models/stt/vosk-model-small-en-us-0.15"   # legacy placeholder (Local AI server now loads via env vars)
    llm_model: "models/llm/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf"
    tts_voice: "models/tts/en_US-lessac-medium.onnx"
    temperature: 0.4
    max_tokens: 64
  deepgram:
    enabled: true
    api_key: "${DEEPGRAM_API_KEY}"
    model: "nova-2-general"
    tts_model: "aura-asteria-en"
    greeting: "${DEEPGRAM_GREETING:-Hello, how can I help you today?}"
    instructions: "${DEEPGRAM_INSTRUCTIONS:-You are a concise voice assistant. Respond in under 20 words and answer immediately.}"
    input_encoding: "linear16"   # Provider audio encoding for inbound caller audio
    input_sample_rate_hz: 8000    # Align to trunk sample rate (8 kHz for telephony)
    continuous_input: true        # Stream audio continuously for best responsiveness
                                  # TIP: Keep this true for real-time conversations
