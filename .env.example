# Asterisk ARI connection (required)
# Copy this file to .env and set real values for your system.
ASTERISK_HOST=127.0.0.1
ASTERISK_ARI_USERNAME=asterisk
ASTERISK_ARI_PASSWORD=asterisk

# Cloud provider credentials (set what you use)
OPENAI_API_KEY=
DEEPGRAM_API_KEY=
# GOOGLE_API_KEY=
# Logging (ai-engine)
# Use console formatting at INFO by default; set LOG_FORMAT=json for machine ingestion.
LOG_FORMAT=console
LOG_LEVEL=info       # debug|info|warning|error|critical
LOG_COLOR=1          # 1=colored console, 0=plain
# Tracebacks policy: auto=only at LOG_LEVEL=debug, always=always include, never=suppress
LOG_SHOW_TRACEBACKS=auto
# LOG_TO_FILE=0      # set to 1 to also write logs to a file
# LOG_FILE_PATH=/mnt/asterisk_media/ai-engine.log  # used when LOG_TO_FILE=1

# Logging (local-ai-server)
# Set to 'warning' to suppress frequent websockets INFO lines from healthchecks.
LOCAL_LOG_LEVEL=info # info|warning|error

# Engine modes (recommended defaults for telephony)
# AUDIO_TRANSPORT can be: audiosocket | externalmedia
AUDIO_TRANSPORT=audiosocket
# DOWNSTREAM_MODE can be: stream | file
DOWNSTREAM_MODE=stream

# AudioSocket listener (when AUDIO_TRANSPORT=audiosocket)
AUDIOSOCKET_HOST=0.0.0.0
AUDIOSOCKET_PORT=8090
AUDIOSOCKET_FORMAT=ulaw  # ulaw | slin16

# Local AI Server (optional; used by local pipelines)
LOCAL_WS_URL=ws://127.0.0.1:8765
LOCAL_WS_CONNECT_TIMEOUT=2.0
LOCAL_WS_RESPONSE_TIMEOUT=5.0
LOCAL_WS_CHUNK_MS=320

# Local AI Server models and performance (optional overrides)
# Tip: smaller LLMs start much faster; switch to larger models for final validation.
# LOCAL_LLM_MODEL_PATH=/app/models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf   # fast startup (recommended)
# LOCAL_LLM_MODEL_PATH=/app/models/llm/llama-2-13b-chat.Q4_K_M.gguf         # large; slower cold-start
# LOCAL_STT_MODEL_PATH=/app/models/stt/vosk-model-en-us-0.22
# LOCAL_TTS_MODEL_PATH=/app/models/tts/en_US-lessac-medium.onnx
# LOCAL_LLM_THREADS=16
# LOCAL_LLM_CONTEXT=4096
# LOCAL_LLM_BATCH=256
# LOCAL_LLM_MAX_TOKENS=32
# LOCAL_LLM_TEMPERATURE=0.2
# LOCAL_LLM_USE_MLOCK=0   # set 1 to use mlock (may require privileges)
# LOCAL_STT_IDLE_MS=3000  # finalize STT after this many ms of silence

# Health endpoint (optional)
# HEALTH_HOST=0.0.0.0
# HEALTH_PORT=15000

# LLM defaults (optional)
GREETING="Hello, how can I help you today?"
AI_ROLE="You are a concise and helpful voice assistant. Keep replies under 20 words unless asked for detail."

# Barge-in tuning overrides (optional)
# BARGE_IN_ENABLED=true
# BARGE_IN_INITIAL_PROTECTION_MS=400
# BARGE_IN_MIN_MS=400
# BARGE_IN_ENERGY_THRESHOLD=1800
# BARGE_IN_COOLDOWN_MS=1000
# BARGE_IN_POST_TTS_END_PROTECTION_MS=250
